\chapter{Topographical Global Optimisation (TGO)}  \label{sec:TGO}
The Topographical Global Optimisation (TGO) was originally conceived by \citet{Torn1990} and Henderson et al. \cite{Henderson2015, Henderson2016} introduced new formalisms and empirical methods to determine hyperparameters described in this section. \citet{Henderson2015} also presents the algorithm in an introductory fashion. It is in essence an iterative clustering algorithm that maps the hypersurface of the objective function into a topography matrix (called a $t$-matrix) and then finds a certain number of starting points referred to as local minimisers. A local search using the local minimisers as starting points is then used to find each minimum from which the global minimum is finally calculated. \citet{Henderson2015} used the feasible direction interior-point method proposed by \citet{Herskovits1998} in this step. The feasible direction interior-point method allows for minimisation of problems with linear and/or nonlinear equality constraints; an extension by \citet{Henderson2015} of the original applications of \citet{Torn1990}. The TGO method consists of three steps:
\begin{enumerate}
\item Uniform random sampling generation of $N$ points in the search space.
\item Construction of the topograph, which is a directed graph with the sampled points as vertices on a $k$-nearest neighbours basis with the direction of the arc directed towards a point with a larger function value.
\item Local minimisation of topograph minimisers. 
\end{enumerate}

\section{Step 1: Random Sampling Point generation} \label{sec:tgo1}
In order to generate the uniform sampling points within $\Omega$ the deterministic Sobol sequence is used in this dissertation \cite{Henderson2015, Sobol1967}. Other possible low discrepancy sequences such as the Halton and Van der Corput sequences \cite{zbMATH03440485} can also be used in this step. An efficient Gray code implementation was proposed by \citet{Antonov1979} wherein a single XOR operation for each dimension can be used to find the next sampling point in the sequence $x_{n,i}=x_{n-1,i} \oplus v_{k,i}. \,$ An adaptation of this method is available in the open source Python library UQToolbox\cite{Bigoni2016}. The Sobol sequenced points are generated within the $n$ dimensional hypercube $ [0, 1]^n~\in ~\mathbb{R}^n $, providing a uniform distribution on the hypersurface within this space. In the current implementation this set of points is stretched across the lower and upper bounds to form the hyperrectangle $[\mathbf{l}, \mathbf{u}]^n = [l_1,~u_1] \times~[l_2,~u_2]  \times \dots \times [l_n,~u_n] \subseteq  \mathbb{R}^n$. The subset of feasible points contained in $\Omega$ is found by discarding any points lying outside the constraints $ \mathbf{g}(\mathbf{x}) > 0$.

\section{Step 2:  Construction of the topograph} \label{sec:tgo2}
The topograph is constructed from the generated sampling points within $\Omega$. From the topograph several global minimisers in $f$ are found using the definitions developed in this chapter which are then used as starting points for local minimisation routines. First $N$ points are selected from the uniformly generated sequence of points within the feasible domain of $\Omega \subset \mathbb{R}^n$. Points generated by the sequence that lie outside the constraints are excluded. The points are denoted by $\bold{p}_i, i = 1, 2, 3 \dots N$. Next for each point $\bold{p}_i $ a reference list is constructed by ordering the other $N -1$ points from their nearest to farthest Euclidean distances. These ordered lists make up the rows of the topography matrix (or topograph). Furthermore, for some point $\bold{p}_j \in \left\{1, 2, 3 \dots (N - 1)\right\}$ in the row with the first entry $\bold{p}_i $, a sign is assigned as follows:
\[ \textrm{sign} (\bold{p}_j) = \begin{cases} 
       f(\bold{p}_j)  \geq f(\bold{p}_i) & \rightarrow +\\
       f(\bold{p}_j) <  f(\bold{p}_i)  & \rightarrow  -
   \end{cases}
\]
In order to demonstrate this construction we will define this ordered list in such a way that the increasing indices represent an ordered list of the nearest points to $\bold{p}_1$, that is $\left\| \mathbf{\bold{p}_{i }} - \mathbf{\bold{p}_{i + 1}} \right\|  \leq \left\| \mathbf{\bold{p}_{i+1 }} - \mathbf{\bold{p}_{i + 2}} \right\|   \forall i$ .  Suppose for example that $f(\bold{p}_2)  \geq f(\bold{p}_1) $,  $f(\bold{p}_3 )< f(\bold{p}_1)$ and $f(\bold{p}_N ) \geq f(\bold{p}_1)$, the resulting topograph with the first row known is:

\begin{equation} \label{eq:tmatrix}
t \textrm{-} \textrm{matrix} =
%  pmatrix bmatrix  Bmatrix  vmatrix  Vmatrix
    \begin{pmatrix}[c|cccc]
  \bold{p}_1 & +\bold{p}_2 		& -\bold{p}_3				& \dots 		&  +\bold{p}_N\\
   \vdots &    \vdots 	&     \vdots 	& \ddots 	&  \vdots\\
   \bold{p}_N & \bold{p}_j 			&  \dots			&  \bold{p}_j 		&  \bold{p}_j \\ 
    \end{pmatrix}
\end{equation}
Note that the remaining rows (represented by unknown points and signs $\bold{p}_j$) are constructed similarly to the first row for every $\bold{p}_i$ row. The topography matrix can be interpreted as a directed graph, where the signs represent the directed arcs on the graph. It should also be noted that if $\mathbf{g}$ contains non-linear constraints then the graphs produced by the topograph may be connected across disconnected and/or non-convex subspaces of $\Omega$.  Example 1 in \Cref{sec:motivation} demonstrates the construction of the topograph numerically.

Given and integer $1 \leq k \leq (N -1)$, the $N \times k$  submatrix obtained by considering only the $k$-nearest neighbours is called the $k$-$t$-matrix. For example for $k =1 $:
\begin{equation}
1 \textrm{-}t \textrm{-} \textrm{matrix} =
%  pmatrix bmatrix  Bmatrix  vmatrix  Vmatrix
    \begin{pmatrix}[c|c]
  \bold{p}_1    & +\bold{p}_2\\
   \vdots   &   \vdots 	\\
   \bold{p}_N  & \bold{p}_j 		\\ 
    \end{pmatrix}
\end{equation}
for $k =2 $:
\begin{equation}
2 \textrm{-} t \textrm{-} \textrm{matrix} =
%  pmatrix bmatrix  Bmatrix  vmatrix  Vmatrix
    \begin{pmatrix} [c|cc]
    \bold{p}_1   &  +\bold{p}_2 		& -\bold{p}_3			\\
    \vdots   &    \vdots 	&     \vdots 	\\
    \bold{p}_N  & \bold{p}_j  &  \bold{p}_j		\ \
    \end{pmatrix}
\end{equation}
and so forth. The  $k$-$t$-matrix is a representation of its $k^+$-topograph where every row forms a directed subgraph.

The following definitions adapted from \citet{Henderson2015} are used to find the global minimisers of the objective function
\begin{definition} \label{def:tgo1}
Given an integer $1 \leq k \leq (N -1)$, the $i$th row of the $k$-$t$-matrix is said to be a positive row, if all its elements have a plus sign. That is iff $ f(\bold{p}_j)  \geq f(\bold{p}_i)  ~\forall j$.
\end{definition}

\begin{definition} \label{def:tgo2}
 Given an integer $1 \leq k \leq (N -1)$,  a sampling point $\bold{p}_i$ has a positive reference in the $k$-$t$-matrix, if there exists $j \neq i$ such that (a) the $j^{th}$ row of the $k$-$t$-matrix is a positive row and (b) the number $+i$ is an element of this $j^{th}$ row. 
\end{definition}

\begin{definition} \label{def:tgo3}
Given an integer $1 \leq k \leq (N -1)$, the sample point $\bold{p}_i$ is called a local minimiser of $f$ in the $k^+$-topograph if the $i^{th}$ row of the $k$-$t$-matrix is a positive row.
\end{definition}

\begin{definition} \label{def:tgo4}
Given an integer $1 \leq k \leq (N -1)$, the sample point $\bold{p}_i$ is a global minimiser of $f$ in the $k^+$-topograph if $\bold{p}_i$ is a local minimiser of $f$ in the $k^+$-topograph and, in addition, $\bold{p}_i$ has no positive references in the $k$-$t$-matrix. 
\end{definition}

The following propositions can be readily demonstrated to show the consistency of the aforementioned definitions \cite{Henderson2015}.

\begin{proposition}  
Given an integer $1 \leq k \leq (N -1)$, the sample point $\bold{p}_i$ is a global minimiser of $f$ in the $k^+$-topograph if and only if the sample point $\bold{p}_i$ is the only minimiser of $f$ in the $k^+$-topograph which is global.
\end{proposition}

\begin{proposition} 
Given an integer $1 \leq k \leq (N -1)$, then the $i$th row of $k$-$t$-matrix is the only positive row of this matrix if and only if the sample point $\bold{p}_i$ is the only minimiser of $f$ in the $k^+$-topograph which is global.
\end{proposition}

\begin{corollary}
 Given an integer $1 \leq k \leq (N -1)$, if the sample point $\bold{p}_i$ is the only local minimiser of $f$ in the $k^+$-topograph, then $\bold{p}_i$ is a global minimiser of $f$ in this graph.
\end{corollary} 

In this publication we will use the paradigm that all local minimisers of $f$ in the $k^+$ -topograph will be used for the local search (Paradigm 2.2 in \citet{Henderson2015}). As described in \cite{Torn1992} the number of local minimisers of $f$ in the $k^+$-topograph is greater than or equal to number of global minimisers in the topograph. We will therefore employ the following definition
\begin{definition}  \label{def:tgo5}
Given an integer $1 \leq k \leq (N -1)$, the minimiser pool $\mathcal{M}^k$ is the set containing all local minimisers $\bold{p}_i$ in the in the $k^+$-topograph. The total number of starting points used in the local search step is equal to the cardinality of the minimiser pool $|\mathcal{M}^k|$. 
\end{definition}

%
The entire point of using $k$-$t$-matrices is because a $t$-matrix will always have at most one local (and thus global) minimiser. This is undesirable since this sampling point is not necessarily the starting point closest to the true global minimum of the objective function. \citet{Henderson2015} developed a semi-empirical formula producing an integer value $k_c$ which is used as an estimate for the optimal value for the integer $k$.
 
 
\section{Step 3: Local minimisation} \label{sec:tgo3}
Each of the minimisers from the  $k_c$-$t$-topograph is now used as a starting point in a local minimisation routine. The resulting minima are used to find the global minimum. Conceivably various local optimisation routines can be used to address a broad class of optimisations problems. For problems with non-linear inequality constraints \citet{Henderson2015} used the feasible direction interior-point method proposed by \citet{Herskovits1998} minimising the objective function $f$ subject to the set of inequality constraint functions $\mathbf{g}$ using the minimiser set as the initial starting points for the algorithm. An algorithm used to solve the feasible direction interior-point method using the set of starting points calculated in step 2 is presented in detail by \citet{Henderson2015}. 

In this publication we will mainly be using the sequential least squares quadratic programming optimisation algorithm (SLSQP) contained in the SciPy library originally developed by Kraft \cite{Kraft1988, Kraft1994}. The Python implementation of the TGO algorithm published under an open source licence uses this algorithm as implemented in the SciPy library \cite{TGOpy, scipy}.
